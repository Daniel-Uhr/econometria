{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Das Estrelas à Indústria: Uma Jornada pela Econometria\n",
    "\n",
    "# 01 - Preparação para a Jornada\n",
    "\n",
    "## Co-Pilto\n",
    "\n",
    "![Daniel1](https://i.imgur.com/cU6XpGR.jpg)\n",
    "\n",
    "**Daniel de Abreu Pereira Uhr**\n",
    "\n",
    "**Formação:** graduação em economia (UFRGS), mestrado e doutorado em Economia (UnB). Realizou pós-doutorado em Economia (FEA/USP). Foi professor visitante na Alberta School of Business at the University of Alberta (Canadá).\n",
    "\n",
    "**Atuação:** Professor Associado II (UFPel), Professor permanente PPGOM/UFPel, Coordenador do PPGOM (2022-), e Diretor do CeMAD.\n",
    "Linhas de pesquisa: Energy Economics, Economia do Meio Ambiente, Análise Econômica do Direito, e Economia do Trabalho.\n",
    "\n",
    "\n",
    "**E as características de nossos futuros pilotos? Quais as habilidades eles já possuem?** \n",
    "\n",
    "\n",
    "## Breve Mapa do Universo da Econometria\n",
    "\n",
    "Para um entendimento geral do avanço temporal do universo econométrico, podemos dividi-la em três fases:\n",
    "\n",
    "**Primeira Fase**: Origens e Desenvolvimento Inicial \n",
    "* Gregos, Egípcios, Árabes, e Galileu Galilei (1564-1642)\n",
    "* Carl Friedrich Gauss (1777-1855)\n",
    "* Francis Galton (1822-1911)\n",
    "* Karl Pearson (1857-1936)\n",
    "* Ronald Fisher (1890-1962)\n",
    "\n",
    "**Segunda Fase**: Formalização e Estabelecimento Teórico\n",
    "* Mínimos Quadrados Ordinários\n",
    "* Teorema de Gauss-Markov\n",
    "* Busca por estimadores eficientes\n",
    "* Busca por estimadores para diferentes estruturas de dados\n",
    "* Estratégias para tratar as fontes de viés\n",
    "\n",
    "**Terceira Fase**: Avanços Computacionais e Econometria Avançada\n",
    "* Inferência Causal\n",
    "* Machine Learning para Inferência Causal\n",
    "\n",
    "\n",
    "## Definição do Plano de Voo\n",
    "\n",
    "* Apresentação do curso\n",
    "* Revisão de Econometria Básica (Fase II)\n",
    "* Modelagem Econométrica (Fase II) - Resposta Qualitativa\n",
    "* Modelagem Econométrica (Fase II) - Variáveis Instrumentais\n",
    "* Modelagem Econométrica (Fase II) - Dados em Painel\n",
    "* Modelagem Econométrica (Fase II) - Dados em Painel - Extensões\n",
    "* Identificação Causal (Fase III) - Contrafactuais e Inferência Causal\n",
    "* Identificação Causal (Fase III) - Randomização e Experimentos\n",
    "* Identificação Causal (Fase III) - Matching e Propensity Score\n",
    "* Identificação Causal (Fase III) - Late - IV\n",
    "* Identificação Causal (Fase III) - Diferenças em Diferenças\n",
    "* Identificação Causal (Fase III) - Controle Sintético\n",
    "* Identificação Causal (Fase III) - Diferenças em Diferenças Sintético\n",
    "\n",
    "## Tecnologia Necessária Para Realizar a Jornada\n",
    "\n",
    "**Livros de Referência**\n",
    "* Hayashi, F. (2000). Econometrics. Princeton University Press.\n",
    "* Wooldridge, J. M. (2010). Econometric analysis of cross section and panel data. MIT press.\n",
    "* Angrist, J. D., & Pischke, J. S. (2009). Mostly harmless econometrics: An empiricist’s companion. Princeton university press.\n",
    "* Cameron, A. C., & Trivedi, P. K. (2005). Microeconometrics: methods and applications. Cambridge university press.\n",
    "* Avaliação Econômica de Projetos e Programas Sociais. (2017). Itaú Social.\n",
    "* Impact Evaluation in Practice. (2016). The World Bank.\n",
    "\n",
    "**Livros Complementares**\n",
    "* Cameron, A. C., & Trivedi, P. K. (2019). Microeconometrics Using Stata (Revised Edition). Stata Press.\n",
    "* Imbens, G. W., & Rubin, D. B. (2015). Causal inference for statistics, social, and biomedical sciences: an introduction. Cambridge University Press.\n",
    "* Angrist, J. D., & Pischke, J. S. (2014). Mastering ‘metrics: The path from cause to effect. Princeton University Press.\n",
    "* Cunningham, S. W. (2021). Causal Inference: The Mixtape. Yale University Press.\n",
    "* Morgan, S. L., & Winship, C. (2015). Counterfactuals and causal inference: Methods and principles for social research. Cambridge University Press.\n",
    "* Pearl, J. (2009). Causality. Cambridge university press.\n",
    "* Pearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference in statistics: A primer. John Wiley & Sons.\n",
    "\n",
    "\n",
    "**Linguagem de Programação:** \n",
    "\n",
    "Vejamos como instalar e utilizar o Python\n",
    "\n",
    "https://www.python.org/downloads/\n",
    "\n",
    "https://code.visualstudio.com/download\n",
    "\n",
    "https://github.com/features/copilot\n",
    "\n",
    "\n",
    "## Primeira Fase: Origens e Desenvolvimento Inicial\n",
    "\n",
    "As primeiras ideias do estimador de Mínimos Quadrados remontam aos gregos e egípcios (na Antiguidade) e aos árabes (na Idade Média). Mas foi Galileu Galilei (1564-1642) que trouxe a primeira ideia de um estimador de Mínimos Quadrados ao estimar a distância de uma nova estrela com relação à terra com base em dados de dois observatórios. Os dados dos observatórios mediam um ângulo diferente dependendo da época do ano. Ele obteve 74 observações sobre esse ângulo e minimizou os erros de observação para obter uma estimativa mais precisa da distância.\n",
    "\n",
    "Entretanto, Andres Marie Legendre, matemático francês, foi quem primeiro publicou um artigo descrevendo o método de Mínimos Quadrados em 1805. Legendre utilizou o método para estimar a órbita de cometas. Andres foi contestado por Carl Friedrich Gauss, Matemático alemão, que disse já ter descoberto o método de mínimos quadrados em 1795, à semelhança de Galilei, para estimar a órbita de um asteroide. Gauss publicou o método em 1809, mas não foi reconhecido por Legendre.\n",
    "\n",
    "O método de Mínimos Quadrados, inicialmente, era adequado para estimação momentos em torno do zero de uma distribuição. Supondo que possuímos uma amostra aleatória $X_{1}, X_{2}, ..., X_{n}$ podemos calcular o \"erro\" de cada observação com base no desvio com relação ao parâmetro verdadeiro. \n",
    "\n",
    "$$\n",
    "erro_{i} = X_{i} - \\mu\n",
    "$$\n",
    "\n",
    "A ideia inicial do estimador seria encontrar o valor de $\\mu$ que minimiza a soma dos erros ($\\sum_{i}^{n} erro_{i}$). Como podemos ter erros positivos e negativos, elevamos ao quadrado (penalizando maiores desvios da média). O estimador para $\\mu$ é o valor do parâmetro que torna a soma dos erros quadrados mínima.\n",
    "\n",
    "$$\n",
    "\\mu^{MQ} = argmin \\sum_{i}^{n} (X_{i} - \\mu)^{2}\n",
    "$$\n",
    "\n",
    "Francis Galton (1822-1911) foi o primeiro a utilizar o método para estimar a relação entre duas variáveis. \n",
    "\n",
    "![Captura de tela 2023-08-14 145030](https://i.imgur.com/BTRdrOB.png)\n",
    "\n",
    "Galton utilizou o método para estimar a relação entre a altura dos pais e dos filhos (Regressão para a Mediocridade em Estatura Hereditária). Ele utilizou o método de Mínimos Quadrados para estimar a reta que melhor se ajustava aos dados. \n",
    "\n",
    "![Captura de tela 2023-08-14 162251](https://i.imgur.com/6xapNZk.png)\n",
    "\n",
    "A Figura é uma “ilustração gráfica de regressão do Galton\"; os círculos dão as alturas médias dos grupos de crianças cujas alturas das médias parentais podem ser lidas da linha AB. A diferença entre a linha CD (desenhada a olho para aproximar os círculos) e AB representa a regressão em direção à mediocridade”.\n",
    "\n",
    "Galton observou que características extremas (por exemplo, altura) nos pais não são transmitidas completamente à sua prole. Em vez disso, as características da prole progridem para um ponto medíocre (um ponto que desde então foi identificado como a média). O termo \"regressão\" descreve que a prole dos pais que se encontram nas caudas da distribuição tenderá a se aproximar do centro, a média, da distribuição.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Alturas fictícias dos pais e dos filhos (em polegadas)\n",
    "alturas_pais = np.array([72.3, 71.2, 70.2, 69.3, 68.3, 67.3, 66.2, 65.5, 64.5])\n",
    "alturas_filhos = np.array([72, 69.7, 69.5, 69, 68.1, 67.2, 67.1, 66.5, 65.8])\n",
    "\n",
    "# Realizar regressão linear usando o NumPy\n",
    "coeficientes = np.polyfit(alturas_pais, alturas_filhos, 1)\n",
    "funcao_regressao = np.poly1d(coeficientes)\n",
    "\n",
    "# Plotar os dados e a linha de regressão\n",
    "plt.scatter(alturas_pais, alturas_filhos, label='Dados')\n",
    "plt.plot(alturas_pais, funcao_regressao(alturas_pais), color='red', label='Regressão Linear')\n",
    "plt.xlabel('Altura dos Pais (polegadas)')\n",
    "plt.ylabel('Altura dos Filhos (polegadas)')\n",
    "plt.title('Regressão Linear de Altura dos Filhos vs. Altura dos Pais (Exemplo de Galton)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Coeficientes da regressão linear\n",
    "print(\"Coeficiente angular (inclinação):\", coeficientes[0])\n",
    "print(\"Coeficiente linear (intercepto):\", coeficientes[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Karl Pearson** foi aluno, colaborador e sucessor de Galton em muitos aspectos. Em 1901, junto com Weldon e Francis Galton fundou a **revista Biometrika** cujo objeto era o desenvolvimento da teoria estatística. Suas contribuições são o desenvolvimento da regressão linear e da correlação. Classificou distribuições de probabilidade e desenvolveu o **teste do qui-quadrado**. Foi o primeiro a **usar o termo \"correlação\" e também o primeiro a usar o termo \"regressão\"**. Ele também foi o primeiro a usar o termo \"distribuição normal\".\n",
    "\n",
    "**Ronald A. Fisher** (1890-1962) foi um estatístico e geneticista britânico, muitas vezes considerado um dos fundadores da estatística moderna e da genética estatística. Fisher estudou matemática na Universidade de Cambridge e teve a oportunidade de interagir com muitos acadêmicos renomados. Alguns dos principais influenciadores e colaboradores de Fisher incluem:Karl Pearson, Egon Pearson (filho de Karl Pearson), William Gosset (conhecido como \"Student\"), Jerzy Neyman (rivais), Frank Yates (aplicações agrícolas), Leonard Darwin (filho de Charles Darwin), e muitos outros. Fisher é conhecido por suas contribuições à estatística, a análise de variância (ANOVA), distribuição de Fisher (teste F), entre outros.\n",
    "\n",
    "Nesse momento a **\"Regressão linear\"** estava amplamente conhecida e com seus fundamentos estatísticos definidos. Em termos gerais, a **regressão linear** é uma técnica estatística que envolve encontrar a melhor linha reta que se ajusta aos dados em um gráfico. Essa linha reta é usada para modelar a relação entre uma variável independente (ou preditora) e uma variável dependente (ou resposta). A regressão linear pode ser simples, quando envolve apenas uma variável independente, ou múltipla, quando envolve várias variáveis independentes. O objetivo da regressão linear é encontrar os coeficientes da equação da linha (ou hiperplano, no caso da regressão múltipla) de modo que a soma dos quadrados dos resíduos (diferenças entre os valores observados e os valores previstos pela linha) seja minimizada. A regressão linear é amplamente usada para modelar relações entre variáveis e fazer previsões com base nos dados.\n",
    "\n",
    "Já o método algébrico mais conhecido para resolução da regressão linear é o de Mínimos Quadrados Ordinários, aquele proposto por Legendre em 1805. Entretanto, convém lembrar que havia a afirmação de que Gauss já possuia a formulação dos Mínimos Quadrados Ordinários desde 1795, e ainda conseguiu conectar o MQO aos princípios da probabilidade e a distribuição normal. Gauss, conseguiu completar os estudos de Laplace e especificar uma forma matemática da densidade de probabilidade para as observações, dependendo de um número finito de parâmetros desconhecidos.\n",
    "\n",
    "Assim, para não confundirmos, a principal diferença entre MQO e regressão linear é que MQO é um método usado para encontrar os coeficientes da regressão linear. Em outras palavras, MQO é a abordagem matemática utilizada para calcular os coeficientes que definem a linha de regressão. A regressão linear, por outro lado, é o conceito mais amplo que se refere à modelagem da relação entre variáveis usando uma linha (ou hiperplano) de melhor ajuste.\n",
    "\n",
    "### Leitura para a Próxima Aula:\n",
    "\n",
    "Capítulo 1 do livro **Econometrics** de Fumio Hayashi (2000).\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
